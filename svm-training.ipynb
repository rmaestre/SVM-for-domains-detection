{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Paradigma labs 2014\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "'\\nParadigma labs 2014\\n'"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm\n",
      "from sklearn import cross_validation\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.externals import joblib\n",
      "\n",
      "import pickle\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def insert_vectorized_line(corpus, labels, line, label, vectors_size, corpus_number_perdomain):\n",
      "    \"\"\"\n",
      "    From a line: \"word1 word2 word3 word4 word5 word6\" and vectors_size = 3\n",
      "    return     : [\"word1 word2 word3\",\"word4 word5 word6\"]\n",
      "    \n",
      "    The return DS is the format to vectorizer (fit_transform) list of words into vectors\n",
      "    \"\"\"\n",
      "    # Get list of words from the line [\"w1\", \"w2\" .... ]\n",
      "    words =  re.findall(r'\\b[a-z]+\\b', line)\n",
      "    if len(words) > 0:\n",
      "        # Create vectors of length = vectors_size\n",
      "        for i in range(0, len(words), vectors_size):\n",
      "            if len(corpus) < corpus_number_perdomain:\n",
      "                # Append line with vectors_size words and the label class\n",
      "                corpus.append(' '.join(words[i:i+vectors_size]))\n",
      "                labels.append(label)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Parameters to control the length of the vectors and the Matrix rows\n",
      "corpus_number_perdomain = 8000\n",
      "vectors_size = 20\n",
      "\n",
      "langs = {0: \"sp\", 1: \"en\"}\n",
      "lang = langs[0]\n",
      "\n",
      "# DS to save corpus and labels\n",
      "corpus = []\n",
      "labels = []\n",
      "\n",
      "# Load corpus from domains review\n",
      "domains = {\"data/%s/electronics/electronics.txt\"%lang:0, \"data/%s/hotels/hotels.txt\"%lang:1}\n",
      "for file_name in domains:\n",
      "    # Load corpus from hotels review\n",
      "    with open(file_name, \"r\") as file_in:\n",
      "        for line in file_in.readlines():\n",
      "            # Update corpus with new vectors\n",
      "            insert_vectorized_line(corpus, labels, line, domains[file_name], vectors_size, corpus_number_perdomain)\n",
      "            if len(corpus) == corpus_number_perdomain:\n",
      "                break\n",
      "    corpus_number_perdomain *= 2\n",
      "            \n",
      "# We need the same length for Matrix and labels\n",
      "assert(len(corpus) == len(labels))\n",
      "print(\"Corpus lenght: %d \" % len(corpus))\n",
      "\n",
      "# Transform corpus of vectors of words into matrix\n",
      "vectorizer = CountVectorizer(min_df=1)\n",
      "X = vectorizer.fit_transform(corpus)\n",
      "X.toarray()\n",
      "\n",
      "# Transform list of labels into array\n",
      "y = array(labels)\n",
      "\n",
      "print(\"Corpus matrix shape: %s \" % str(X.shape))\n",
      "print(\"Labels vector shape: %s \" % str(y.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Training and validation data (k-fold)\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3, random_state=1)\n",
      "\n",
      "\n",
      "# With a RBF kernel, gamma=0.01, corpus_number_perdomain = 5000 and\n",
      "# vectors_size = 20 to reach the maximun score, however we\n",
      "# use a linear kernel because we have a 0.1 less preccison but we less \n",
      "# support vectors. This is important in classification time\n",
      "\n",
      "clf = svm.SVC(kernel='linear', probability=False)\n",
      "\n",
      "# Clasify\n",
      "clf.fit(X_train, y_train) \n",
      "\n",
      "# Save model to disk and also a vectorizer index\n",
      "joblib.dump(clf, 'models/%s/svm_model.pkl'%lang)\n",
      "with open('models/%s/vectorizer.pkl'%lang, 'wb') as o_file:\n",
      "    pickle.dump(vectorizer, o_file)\n",
      "\n",
      "# Dump info about the model\n",
      "print(\"\\nSupported vectors length: %s\" % str(clf.support_vectors_.shape))\n",
      "print(\"Dual coef. length: %s\" % str(clf.dual_coef_.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Supported vectors length: (2348, 10034)\n",
        "Dual coef. length: (1, 2348)\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "score = clf.score(X_test, y_test)\n",
      "print(\"\\nScore k-fold validation: %.4f%%\" % round(score, 4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Score k-fold validation: 0.9805%\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# I love the equalizer in my new scotch walkman\n",
      "# The cell batery works bad\n",
      "# The hotel is in a great location close to all that downtown Portsmouth has to offer\n",
      "# We had a shot of scotch whiskey at the hotel bar\n",
      "sample = vectorizer.transform(['We had a shot of scotch whiskey at the hotel bar']).toarray()\n",
      "print(sample.shape)\n",
      "print(clf.predict(sample))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1, 10034)\n",
        "[1]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}